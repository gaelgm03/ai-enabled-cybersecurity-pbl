# Week 5 Evaluation Results

**Generated:** 2026-01-14 14:11:36 UTC

---

## Overall Comparison

| Model | Precision | Recall | F1 | FPR | Accuracy | Avg Latency |
|-------|-----------|--------|-----|-----|----------|-------------|
| baseline | 0.9091 | 0.6667 | 0.7692 | 0.0667 | 0.8000 | 0ms |

### Best Models

- **Best F1:** baseline
- **Best Precision:** baseline
- **Best Recall:** baseline
- **Lowest FPR:** baseline

---

## Per-Category Results

### SECRET

| Model | Precision | Recall | F1 | FPR |
|-------|-----------|--------|-----|-----|
| baseline | 0.8571 | 0.6000 | 0.7059 | 0.1000 |

### SQLI

| Model | Precision | Recall | F1 | FPR |
|-------|-----------|--------|-----|-----|
| baseline | 1.0000 | 0.6000 | 0.7500 | 0.0000 |

### TYPO

| Model | Precision | Recall | F1 | FPR |
|-------|-----------|--------|-----|-----|
| baseline | 0.8889 | 0.8000 | 0.8421 | 0.1000 |

---

## Analysis

### Where AI Helps

- **False positive reduction:** AI models can distinguish between real vulnerabilities and benign patterns
- **Context awareness:** AI understands that placeholder values like `YOUR_API_KEY` are not real secrets
- **Semantic understanding:** AI can identify that variable names like `teh` are intentional identifiers

### Where AI May Fail

- **Inconsistent responses:** Same input may get different classifications across runs
- **Hallucination risk:** AI may invent rationales not supported by the code
- **Latency cost:** AI classification is significantly slower than regex matching

### Methodology Notes

- **Ground truth:** Manually labeled dataset with clear vulnerable/safe examples
- **Metrics:** Standard precision, recall, F1 computed per category
- **Limitations:** Small dataset (N<100); results are directional, not statistically significant

---

*Generated by Week 5 Evaluation Harness*