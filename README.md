# AI-Enabled Cybersecurity (PBL)

## MIT Blended AI+X Program  
**Project-Based Learning: AI in Cybersecurity â€“ Anthropic Project**  
**Track 3: AI-Enabled Cybersecurity**

---

## ğŸ“Œ Project Overview

This repository contains the work for the **AI in Cybersecurity Project-Based Learning (PBL)** as part of the **MIT Blended AI+X Program**.

The project explores how **Large Language Models (LLMs)** can be used to **assist defensive cybersecurity tasks**, such as identifying software vulnerabilities, supporting security audits, and automating parts of penetration testing workflowsâ€”while carefully considering the **risks, limitations, and ethical concerns** introduced by AI systems.

---

## ğŸ¯ Project Goals

- Understand how LLMs introduce **new security risks and attack surfaces**
- Explore how AI can support **defensive cybersecurity workflows**
- Identify common **software vulnerabilities** and how AI may assist in detecting or explaining them
- Design and prototype a **lightweight AI-assisted cybersecurity tool**
- Apply **responsible AI principles**, including human-in-the-loop validation

---

## ğŸ§­ Track Information

**Track:** Track 3 â€“ AI-Enabled Cybersecurity  

**Track Focus Areas:**
- Foundations of penetration testing and vulnerability research  
- AI-assisted security audits and system testing  
- Identifying code vulnerabilities with LLMs  
- Prompt engineering and scaffolding for security use cases  
- Proofs-of-concept for AI-enabled cybersecurity workflows  

---

## ğŸ—‚ï¸ Repository Structure

ai-enabled-cybersecurity-pbl/
â”‚
â”œâ”€â”€ docs/ # References, diagrams, and documentation
â”œâ”€â”€ notes/ # Weekly reflections, findings, and discussions
â”œâ”€â”€ experiments/ # Vulnerability examples and prompt experiments
â”œâ”€â”€ src/ # Source code for AI-assisted tools (future work)
â”œâ”€â”€ README.md # Project overview and documentation
â””â”€â”€ .gitignore

---

## ğŸ“… Week 1 Focus

**Week 1 Objectives (Track 3):**
- Gain familiarity with **Git** and collaborative workflows
- Build foundational understanding of **software vulnerabilities**
- Frame vulnerabilities in the context of **AI-assisted security analysis**

**Week 1 Progress:**
- Repository setup and team collaboration established  
- Core Git workflows practiced (branching, commits, pull requests)  
- Review of common vulnerability types (e.g., injection, access control, misconfiguration)  
- Initial discussion on how LLMs can assist or introduce risks in cybersecurity  

---

## âš ï¸ Ethical & Security Considerations

This project is conducted strictly for **educational and defensive purposes**.  
All experiments and tools developed will:
- Avoid unauthorized or unethical security testing
- Respect data privacy and confidentiality
- Include human oversight for AI-generated outputs
- Align with responsible AI and cybersecurity best practices

---

## ğŸš€ Next Steps

- Narrow the initial vulnerability scope
- Design the AI-assisted security workflow
- Begin prototyping and evaluation of LLM outputs
- Define success metrics and limitations

---

## ğŸ‘¥ Team

- **Gael GuzmÃ¡n**  
- *Additional team members to be added*

---

## ğŸ“ License & Usage

This repository is intended for **academic use** within the MIT Blended AI+X Program.  
No content should be used for malicious or unauthorized security activities.
